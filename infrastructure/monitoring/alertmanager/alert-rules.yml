groups:
  - name: outbox_alerts
    interval: 15s
    rules:
      # Alert when there's a high backlog of pending events
      - alert: HighOutboxBacklog
        expr: outbox_events_pending > 100
        for: 5m
        labels:
          severity: warning
          application: catbox-server
        annotations:
          summary: "High number of pending outbox events"
          description: "There are {{ $value }} pending events in the outbox for more than 5 minutes. Normal operation should keep this below 100."

      # Alert when event processing is stalled
      - alert: StalledOutboxProcessing
        expr: outbox_events_oldest_age_seconds > 300
        for: 2m
        labels:
          severity: critical
          application: catbox-server
        annotations:
          summary: "Outbox event processing appears to be stalled"
          description: "The oldest unsent event is {{ $value }} seconds old (>5 minutes). Events should be processed within seconds. Check if catbox-server is running and healthy."

      # Alert on high failure rate
      - alert: HighOutboxFailureRate
        expr: rate(outbox_events_published_failure_total[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
          application: catbox-server
        annotations:
          summary: "High rate of event publishing failures"
          description: "Event publishing is failing at {{ $value }} events/second. Check Kafka connectivity and broker health."

      # Alert on slow processing performance
      - alert: SlowOutboxProcessing
        expr: histogram_quantile(0.95, rate(outbox_events_processing_duration_seconds_bucket[5m])) > 10
        for: 5m
        labels:
          severity: warning
          application: catbox-server
        annotations:
          summary: "Outbox event processing is slow"
          description: "95th percentile processing time is {{ $value }} seconds (>10s). This may indicate performance issues or high load."

      # Alert when events are moved to dead letter queue
      - alert: DeadLetterQueueGrowth
        expr: increase(outbox_events_deadletter_total[5m]) > 0
        for: 1m
        labels:
          severity: critical
          application: catbox-server
        annotations:
          summary: "Events being moved to dead letter queue"
          description: "{{ $value }} events have been moved to the dead letter queue in the last 5 minutes. These events have exceeded retry limits and require manual investigation."

      # Alert when archive table is getting very large
      - alert: ArchiveTableLargeSize
        expr: outbox_events_archived_total > 1000000
        for: 10m
        labels:
          severity: warning
          application: catbox-server
        annotations:
          summary: "Outbox archive table is very large"
          description: "Archive table contains {{ $value }} events (>1 million). Consider implementing data retention policies to purge old archived events."

      # Alert when there are any pending events for an extended period
      - alert: CriticalOutboxBacklog
        expr: outbox_events_pending > 1000
        for: 10m
        labels:
          severity: critical
          application: catbox-server
        annotations:
          summary: "Critical backlog of pending outbox events"
          description: "There are {{ $value }} pending events in the outbox (>1000). This indicates a serious performance or connectivity issue. Immediate attention required."

      # Alert when no events are being processed (system might be down)
      - alert: NoEventProcessing
        expr: rate(outbox_events_published_success_total[10m]) == 0 and outbox_events_pending > 0
        for: 5m
        labels:
          severity: critical
          application: catbox-server
        annotations:
          summary: "No events being processed despite pending events"
          description: "There are {{ $value }} pending events but no successful publishes in the last 10 minutes. The catbox-server may be down or unable to connect to Kafka."

  - name: application_health
    interval: 30s
    rules:
      # Alert when application is down (no metrics being scraped)
      - alert: CatboxServerDown
        expr: up{job="catbox-server"} == 0
        for: 2m
        labels:
          severity: critical
          application: catbox-server
        annotations:
          summary: "Catbox Server is down"
          description: "The catbox-server application is not responding to Prometheus scrapes. Check if the application is running and healthy."

      - alert: OrderServiceDown
        expr: up{job="order-service"} == 0
        for: 2m
        labels:
          severity: critical
          application: order-service
        annotations:
          summary: "Order Service is down"
          description: "The order-service application is not responding to Prometheus scrapes. Check if the application is running and healthy."

  - name: jvm_alerts
    interval: 30s
    rules:
      # Alert on high JVM memory usage
      - alert: HighJVMMemoryUsage
        expr: (jvm_memory_used_bytes{area="heap"} / jvm_memory_max_bytes{area="heap"}) > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High JVM heap memory usage"
          description: "JVM heap memory usage is {{ $value | humanizePercentage }} (>90%). Consider increasing heap size or investigating memory leaks."

      # Alert on frequent garbage collection
      - alert: FrequentGarbageCollection
        expr: rate(jvm_gc_pause_seconds_count[5m]) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Frequent garbage collection detected"
          description: "GC is running {{ $value }} times per second. This may indicate memory pressure or inefficient memory usage patterns."
